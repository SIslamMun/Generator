# ============================================================================
# QA GENERATION PROMPT (Instruction Backtranslation)
# Paper: Self-Alignment with Instruction Backtranslation (Meta AI, 2024)
# Treats document chunks as "answers" and generates questions
# ============================================================================
qa_generation: |
  Create question-answer pairs from this text for LLM training.

  Rules:
  1. Questions must be about important facts in the text
  2. Answers must be directly supported by the text
  3. Create {n_pairs} diverse question-answer pairs
  4. IMPORTANT: Work with whatever text is provided, even if limited
  5. Extract facts from titles, headers, or any available content
  6. Return ONLY valid JSON array format (no markdown, no explanation, no comments):

  [
    {{
      "question": "Question 1?",
      "answer": "Answer 1."
    }},
    {{
      "question": "Question 2?",
      "answer": "Answer 2."
    }}
  ]

  Text:
  {text}

# ============================================================================
# QA RATING PROMPT (LLM-as-Judge)
# Papers: AlpaGasus (2023), LIMA (2023)
# Rates QA pairs on quality 1-10, filter by threshold
# ============================================================================
qa_rating: |
  You are an expert evaluator. Rate these question-answer pairs on a scale of 1-10.

  Criteria:
  - Clarity (0-3): Question clear? Answer understandable?
  - Accuracy (0-3): Answer correct and supported by evidence?
  - Usefulness (0-2): Valuable for training?
  - Difficulty (0-2): Appropriate complexity?

  Rate STRICTLY - most pairs should score 5-7. Only exceptional pairs score 8+.

  Return valid JSON with ratings:
  [
    {{"question": "Original question", "answer": "Original answer", "rating": 7}},
    {{"question": "Original question", "answer": "Original answer", "rating": 5}}
  ]

  QA pairs to rate:
  {pairs}

# ============================================================================
# COT GENERATION (Future - Priority 3)
# Paper: Distilling Step-by-Step (Google, 2023)
# Approach 1: Generate NEW CoT examples from documents
# ============================================================================
cot_generation: |
  Create complex reasoning examples from this text that demonstrate chain-of-thought thinking.

  Each example should have:
  1. A challenging question that requires step-by-step reasoning
  2. Detailed reasoning steps that break down the problem
  3. A concise final answer

  Return JSON format only:

  [
    {{
      "question": "Complex question about the text?",
      "reasoning": "Step 1: First, I need to consider...\nStep 2: Then, I analyze...\nStep 3: Finally, I can conclude...",
      "answer": "Final answer based on the reasoning."
    }}
  ]

  Text:
  {text}

# ============================================================================
# COT ENHANCEMENT (Future - Priority 3)
# Paper: Distilling Step-by-Step (Google, 2023)
# Approach 2: Add CoT reasoning to EXISTING QA pairs
# ============================================================================
cot_enhancement: |
  You are an expert reasoning assistant. Your task is to enhance the given conversations by adding chain-of-thought reasoning.

  For each conversation, add detailed step-by-step reasoning to the assistant's responses while preserving the original answer.

  Return the enhanced conversations as a JSON array matching this format:
  [
    [
      {{"role": "system", "content": "System message"}},
      {{"role": "user", "content": "User question"}},
      {{"role": "assistant", "content": "Let me think through this step by step:\n\n1. First, I need to consider...\n2. Then...\n\nTherefore, [original answer]"}}
    ]
  ]

  Original conversations:
  {conversations}
